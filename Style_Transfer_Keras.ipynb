{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer - Keras "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import pacakges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imsave\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "\n",
    "# Keras Components\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications import vgg19\n",
    "\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"inputs/cat.jpg\" alt=\"Drawing\" style=\"height: 320px; float:left; margin:0px; margin-left:10px\"/><img src=\"inputs/flowers.jpg\" alt=\"Drawing\" style=\"height: 320px; float:left; margin:0px; margin-left:10px\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_image_path = 'inputs/cat.jpg'\n",
    "style_reference_image_path = 'inputs/flowers.jpg'\n",
    "\n",
    "display(HTML(  '<img src=\"%s\" alt=\"Drawing\" style=\"height: 320px; float:left; margin:0px; margin-left:10px\"/>'*2 % (base_image_path,style_reference_image_path) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Style Transfer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of style transfer is to generate a \"combination\" image with the same \"content\" as a base image, but with the \"style\" of a different picture. This is achieved by optermising the weighted sum of 3 loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Style Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The style loss is where the deep learning keeps in --that one is defined\n",
    "using a deep convolutional neural network. Precisely, it consists in a sum of\n",
    "L2 distances between the Gram matrices of the representations of\n",
    "the base image and the style reference image, extracted from\n",
    "different layers of a convnet (trained on ImageNet). The general idea\n",
    "is to capture color/texture information at different spatial\n",
    "scales (fairly large scales --defined by the depth of the layer considered)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The content loss is a L2 distance between the features of the base\n",
    "image (extracted from a deep layer) and the features of the combination image,\n",
    "keeping the generated image close enough to the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Variation Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imposes local spatial continuity between the pixels of the combination image, giving it visual coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n",
    "        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n",
    "    else:\n",
    "        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output Image Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensor Representations of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_image = K.variable(preprocess_image(base_image_path, img_nrows, img_ncols ))\n",
    "style_reference_image = K.variable(preprocess_image(style_reference_image_path, img_nrows, img_ncols ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder that will contain our generated image\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n",
    "else:\n",
    "    combination_image = K.placeholder((1, img_nrows, img_ncols, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Representations of Tensors (vgg19) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine the 3 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image, style_reference_image, combination_image], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build the VGG16 network with our 3 images as input\n",
    "# the model will be loaded with pre-trained ImageNet weights\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,weights='imagenet', include_top=False)\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "outputs_dict = { layer.name : layer.output for layer in model.layers }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Loss/gradient functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the weights of each of each loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_variation_weight, style_weight, content_weight = 1.0, 0.025, 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Combine these loss functions into a single scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = K.variable(0.)\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss += content_weight * content_loss(base_image_features, combination_features)\n",
    "\n",
    "feature_layers = ['block1_conv1', 'block2_conv1','block3_conv1', 'block4_conv1','block5_conv1']\n",
    "\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss += (style_weight / len(feature_layers)) * sl\n",
    "loss += total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "get the gradients of the generated image wrt the loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads = K.gradients(loss, combination_image)\n",
    "outputs = [loss] + grads if isinstance(grads, (list, tuple) ) else [loss, grads ] \n",
    "f_outputs = K.function([combination_image], outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((1, 3, img_nrows, img_ncols))\n",
    "    else:\n",
    "        x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "this Evaluator class makes it possible to compute loss and gradients in one pass while retrieving them via two separate functions, \"loss\" and \"grads\". This is done because scipy.optimize requires separate functions for loss and gradients, but computing them separately would be inefficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "    \n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "    \n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
    "so as to minimize the neural style loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0\n",
      "Current loss value: 2.05206e+09\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"outputs/combination_at_iteration_0.png\" alt=\"Drawing\" style=\"height: 320px; margin:0px; margin-bottom:10px\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as outputs/combination_at_iteration_0.png\n",
      "Start of iteration 1\n",
      "Start of iteration 2\n",
      "Start of iteration 3\n",
      "Start of iteration 4\n",
      "Start of iteration 5\n",
      "Start of iteration 6\n",
      "Start of iteration 7\n",
      "Start of iteration 8\n",
      "Start of iteration 9\n",
      "Start of iteration 10\n",
      "Start of iteration 11\n",
      "Start of iteration 12\n",
      "Start of iteration 13\n",
      "Start of iteration 14\n",
      "Start of iteration 15\n",
      "Start of iteration 16\n",
      "Start of iteration 17\n",
      "Start of iteration 18\n",
      "Start of iteration 19\n",
      "Start of iteration 20\n"
     ]
    }
   ],
   "source": [
    "## initialise with \n",
    "x = preprocess_image(- , img_nrows, img_ncols )\n",
    "\n",
    "iterations = 400\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Start of iteration', i)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.grads, maxfun=20)\n",
    "    if i % 20 == 0:\n",
    "        print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy() , img_nrows, img_ncols )\n",
    "    fname = 'outputs/combination_at_iteration_%d.png' % i\n",
    "    imsave(fname, img)\n",
    "    end_time = time.time()\n",
    "    if i % 20 == 0:\n",
    "        display(HTML(  '<img src=\"%s\" alt=\"Drawing\" style=\"height: 320px; margin:0px; margin-bottom:10px\"/>' % fname ))\n",
    "        print('Image saved as', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
